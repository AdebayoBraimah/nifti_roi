{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variable(s)\n",
    "# scripts_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "scripts_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Command():\n",
    "    '''\n",
    "    Creates a command and an empty command list for UNIX command line programs/applications. Primary use and\n",
    "    use-cases are intended for the subprocess module and its associated classes (i.e. call/run).\n",
    "    Attributes:\n",
    "        command: Command to be performed on the command line\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init doc-string for Command class.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def init_cmd(self, command):\n",
    "        '''\n",
    "        Init command function for initializing commands to be used on UNIX command line.\n",
    "        \n",
    "        Arguments:\n",
    "            command (string): Command to be used. Note: command used must be in system path\n",
    "        Returns:\n",
    "            cmd_list (list): Mutable list that can be appended to.\n",
    "        '''\n",
    "        self.command = command\n",
    "        self.cmd_list = [f\"{self.command}\"]\n",
    "        return self.cmd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cmd_list,stdout=\"\",stderr=\"\"):\n",
    "    '''\n",
    "    Uses python's built-in subprocess class to run a command from an input command list.\n",
    "    The standard output and error can optionally be written to file.\n",
    "    \n",
    "    Arguments:\n",
    "        cmd_list(list): Input command list to be run from the UNIX command line.\n",
    "        stdout(file): Output file to write standard output to.\n",
    "        stderr(file): Output file to write standard error to.\n",
    "    Returns:\n",
    "        stdout(file): Output file that contains the standard output.\n",
    "        stderr(file): Output file that contains the standard error.\n",
    "    '''\n",
    "    if stdout and stderr:\n",
    "        with open(stdout,\"w\") as file:\n",
    "            with open(stderr,\"w\") as file_err:\n",
    "                subprocess.call(cmd_list,stdout=file,stderr=file_err)\n",
    "                file.close(); file_err.close()\n",
    "    elif stdout:\n",
    "        with open(stdout,\"w\") as file:\n",
    "            subprocess.call(cmd_list,stdout=file)\n",
    "            file.close()\n",
    "        stderr = None\n",
    "    else:\n",
    "        subprocess.call(cmd_list)\n",
    "        stdout = None\n",
    "        stderr = None\n",
    "\n",
    "    return stdout,stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_loc(coords,vol_atlas_num=3):\n",
    "    '''\n",
    "    Uses input list of X,Y,Z MNI space mm coordinates to identify ROIs.\n",
    "    \n",
    "    NOTE: External bash script is used.\n",
    "    \n",
    "    Arguments:\n",
    "        coords(list): Coordinate list with a lenth of 3 that corresponds to the XYZ coordinates of some ROI in MNI space.\n",
    "        vol_atlas_num(int): Atlas to be used in FSL's `atlasquery`. Number corresponds to an atlas. See FSL's `atlasquery` help menu for details.\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs generated from input coordinates.\n",
    "    '''\n",
    "    \n",
    "    # Define volume atlas number dictionary\n",
    "    vol_atlas_dict = {\n",
    "    1: \"Cerebellar Atlas in MNI152 space after normalization with FLIRT\",\n",
    "    2: \"Cerebellar Atlas in MNI152 space after normalization with FNIRT\",\n",
    "    3: \"Harvard-Oxford Cortical Structural Atlas\",\n",
    "    4: \"Harvard-Oxford Subcortical Structural Atlas\",\n",
    "    5: \"Human Sensorimotor Tracts Labels\",\n",
    "    6: \"JHU ICBM-DTI-81 White-Matter Labels\",\n",
    "    7: \"JHU White-Matter Tractography Atlas\",\n",
    "    8: \"Juelich Histological Atlas\",\n",
    "    9: \"MNI Structural Atlas\",\n",
    "    10: \"Mars Parietal connectivity-based parcellation\",\n",
    "    11: \"Mars TPJ connectivity-based parcellation\",\n",
    "    12: \"Neubert Ventral Frontal connectivity-based parcellation\",\n",
    "    13: \"Oxford Thalamic Connectivity Probability Atlas\",\n",
    "    14: \"Oxford-Imanova Striatal Connectivity Atlas 3 sub-regions\",\n",
    "    15: \"Oxford-Imanova Striatal Connectivity Atlas 7 sub-regions\",\n",
    "    16: \"Oxford-Imanova Striatal Structural Atlas\",\n",
    "    17: \"Sallet Dorsal Frontal connectivity-based parcellation\",\n",
    "    18: \"Subthalamic Nucleus Atlas\",\n",
    "    19: \"Talairach Daemon Labels\"}\n",
    "    \n",
    "    # Define list and output file\n",
    "    roi_list = list()\n",
    "    out_file = \"subcort.rois.txt\"\n",
    "    \n",
    "    if len(coords) == 3:\n",
    "        atlasq_cmd = os.path.join(scripts_dir,\"atlasq.sh\")\n",
    "        atlasq = Command().init_cmd(atlasq_cmd)\n",
    "        atlasq.append(f\"--coord\")\n",
    "        atlasq.append(f\"\\\"{coords[0]},{coords[1]},{coords[2]}\\\"\")\n",
    "        atlasq.append(\"--atlas-num\")\n",
    "        atlasq.append(f\"{vol_atlas_num}\")\n",
    "    \n",
    "        run(atlasq,out_file)\n",
    "\n",
    "        with open(out_file,\"r\") as file:\n",
    "            text = file.readlines()\n",
    "            for i in range(0,len(text)):\n",
    "                text[i] = re.sub(f\"<b>{vol_atlas_dict[vol_atlas_num]}</b><br>\",\"\",text[i].rstrip())\n",
    "\n",
    "        os.remove(out_file)\n",
    "        \n",
    "        if len(text) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            roi_list.extend(text) \n",
    "        \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vol_clust(nii_file,thresh=0.95,dist=0,vol_atlas_num=3):\n",
    "    '''\n",
    "    Identifies clusters in a volumetric (NIFTI) file.\n",
    "    \n",
    "    Arguments:\n",
    "        nii_file(file): Input NIFTI file\n",
    "        thresh(float): Cluster minimum threshold\n",
    "        dist(float): Minimum distance between clusters\n",
    "        vol_atlas_num(int): Atlas to be used in FSL's `atlasquery`. Number corresponds to an atlas. See FSL's `atlasquery` help menu for details.\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs that overlap with some given cluster\n",
    "    '''\n",
    "    \n",
    "    out_file = \"vol.cluster.tsv\"\n",
    "    \n",
    "    roi_list = list()\n",
    "    tmp_list = list()\n",
    "    \n",
    "    vol_clust = Command().init_cmd(\"cluster\")\n",
    "    \n",
    "    vol_clust.append(f\"--in={nii_file}\")\n",
    "    vol_clust.append(f\"--thresh={thresh}\")\n",
    "    vol_clust.append(f\"--peakdist={dist}\")\n",
    "    vol_clust.append(\"--mm\")\n",
    "    \n",
    "    run(vol_clust,out_file)\n",
    "    \n",
    "    df_tmp = pd.read_csv(out_file,sep=\"\\t\")\n",
    "    \n",
    "    os.remove(out_file)\n",
    "    \n",
    "    df = df_tmp[['MAX X (mm)','MAX Y (mm)','MAX Z (mm)']].copy()\n",
    "    \n",
    "    for i in range(0,len(df)):\n",
    "        coord_list=[df['MAX X (mm)'][i],df['MAX Y (mm)'][i],df['MAX Z (mm)'][i]]\n",
    "        tmp_list = roi_loc(coord_list,vol_atlas_num)\n",
    "        if len(tmp_list) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            roi_list.extend(tmp_list)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_atlas_file(atlas_info):\n",
    "    '''\n",
    "    Reads CSV of key, value pairs of enumerated ROIs for some corresponding atlas.\n",
    "    \n",
    "    Arguments:\n",
    "        atlas_info(file): Input CSV file of enumerated ROI key, value pairs\n",
    "    Returns:\n",
    "        atlas_dict(dict): Dictionary of atlas key, value pairs\n",
    "    '''\n",
    "    \n",
    "    atlas_info = os.path.abspath(atlas_info)\n",
    "    df = pd.read_csv(atlas_info,header=None); df.columns = ['key', 'id']\n",
    "    # df = pd.read_csv(atlas_info,header=None,error_bad_lines=False); df.columns = ['key', 'id']\n",
    "    atlas_dict = df.set_index('key').to_dict(orient='dict')['id']\n",
    "    \n",
    "    return atlas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ext(file):\n",
    "    '''\n",
    "    Removes extension of some input file string. Primarily intended for NIFTI files.\n",
    "    \n",
    "    Arguments:\n",
    "        file(str): Input file name string\n",
    "    Returns:\n",
    "        name(str): File name string with extension removed\n",
    "    '''\n",
    "    \n",
    "    if '.nii.gz' in file:\n",
    "        name = file[:-7]\n",
    "    elif '.nii' in file:\n",
    "        name = file[:-4]\n",
    "    elif '.txt' in file or '.tsv' in file or '.csv' in file:\n",
    "        name = file\n",
    "    else:\n",
    "        name = file\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_dtype(img,data_type=\"int\"):\n",
    "    '''\n",
    "    Converts image data type to some other arbitrary data type. See fslmaths help menu for further details.\n",
    "    \n",
    "    Arguments:\n",
    "        img(NIFTI file): Input NIFTI file\n",
    "        data_type(str): Output data type (e.g. 'int','float','char','float','double')\n",
    "    Returns:\n",
    "        out_file(NIFTI file): NIFTI file with desired data type\n",
    "    '''\n",
    "    \n",
    "    img = os.path.abspath(img)\n",
    "    out_dir = os.path.dirname(img)\n",
    "    \n",
    "    img = remove_ext(img)\n",
    "    name = os.path.basename(img)\n",
    "    \n",
    "    out_file = os.path.join(out_dir,name + \".int\" + \".nii.gz\")\n",
    "    \n",
    "    img_dtype = Command().init_cmd(\"fslmaths\")\n",
    "    img_dtype.append(\"-dt\")\n",
    "    img_dtype.append(data_type)\n",
    "    img_dtype.append(img)\n",
    "    img_dtype.append(out_file)\n",
    "    img_dtype.append(\"-odt\")\n",
    "    img_dtype.append(data_type)\n",
    "    \n",
    "    run(img_dtype)\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atlas_data(nii_atlas,atlas_info,data_type=\"int\"):\n",
    "    '''\n",
    "    Loads atlas data from input NIFTI neuroimage atlas and it's corresponding\n",
    "    enumerated key, value paired atlas CSV file.\n",
    "    \n",
    "    Arguments:\n",
    "        nii_atlas(NIFTI file): Input NIFTI atlas\n",
    "        atlas_info(file): Corresponding atlas CSV file\n",
    "        data_type(str): Output data type (e.g. 'int','float','char','float','double')\n",
    "    Returns:\n",
    "        atlas_data(numpy array): Atlas data represented as an N x M x P array\n",
    "        atlas_dict(dict): Atlas dictionary of key, value pairs\n",
    "    '''\n",
    "    \n",
    "    # Load atlas key/ID information\n",
    "    atlas_dict = read_atlas_file(atlas_info)\n",
    "    \n",
    "    # Convert input image from float to int\n",
    "    int_data = convert_img_dtype(nii_atlas,data_type)\n",
    "    \n",
    "    # Load/export data as numpy array\n",
    "    img = nib.load(int_data)\n",
    "    atlas_data = img.get_fdata()\n",
    "    \n",
    "    # Clean-up\n",
    "    os.remove(int_data)\n",
    "    \n",
    "    return atlas_data,atlas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cluster_vol(nii_file,thresh=0.95,dist=0):\n",
    "    '''\n",
    "    Creates enumerated clusters from input NIFTI file and writes the enumerated clusters to a separate NIFTI volume.\n",
    "    \n",
    "    Arguments:\n",
    "        nii_file(NIFTI file): Input NIFTI file\n",
    "        thresh(float): Minimum threshold \n",
    "        dist(float): Minimum distance between clusters\n",
    "    Returns:\n",
    "        out_file(NIFTI file): Output NIFTI file of enumerated clusters\n",
    "        out_stat(file): Corresponding table of enumerated clusters with MNI space mm and vox coordinates\n",
    "    '''\n",
    "    \n",
    "    # Construct file paths\n",
    "    nii_file = os.path.abspath(nii_file)\n",
    "    out_dir = os.path.dirname(nii_file)\n",
    "    \n",
    "    nii_file = remove_ext(nii_file)\n",
    "    name = os.path.basename(nii_file)\n",
    "    out_prefix = os.path.join(out_dir,name + \".cluster\")\n",
    "    \n",
    "    out_file = out_prefix + \".nii.gz\"\n",
    "    out_stat = out_prefix + \".txt\"\n",
    "    \n",
    "    # Make cluster(s) from input data\n",
    "    clust_cmd = Command().init_cmd(\"cluster\")\n",
    "    clust_cmd.append(f\"--in={nii_file}\")\n",
    "    clust_cmd.append(f\"--thresh={thresh}\")\n",
    "    clust_cmd.append(f\"--peakdist={dist}\")\n",
    "    clust_cmd.append(f\"--oindex={out_file}\")\n",
    "    # clust_cmd.append(f\"--othresh={out_file}\")\n",
    "    \n",
    "    run(clust_cmd,out_stat)\n",
    "    \n",
    "    return out_file,out_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii_vol(nii_file,thresh=0.95,dist=0):\n",
    "    '''\n",
    "    Reads in NIFTI volume information, creates a volume of enumerated clusters, and then stores \n",
    "    those clusters in an N x M x P array.\n",
    "    \n",
    "    Arguments:\n",
    "        nii_file(NIFTI file): Input NIFTI file\n",
    "        thresh(float): Minimum threshold\n",
    "        dist(float): Minimum distance between clusters\n",
    "    Returns:\n",
    "        img_data(numpy array): N x M x P numpy array of the clusters\n",
    "    '''\n",
    "    \n",
    "    # Create volume clusters\n",
    "    [clust_file,clust_stat] = make_cluster_vol(nii_file,thresh,dist)\n",
    "    \n",
    "    # Load/export data as numpy array\n",
    "    img = nib.load(clust_file)\n",
    "    img_data = img.get_fdata()\n",
    "    \n",
    "    # Clean-up\n",
    "    os.remove(clust_file)\n",
    "    os.remove(clust_stat)\n",
    "    \n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_name(cluster_data,atlas_data,atlas_dict):\n",
    "    '''\n",
    "    Finds ROI names from overlapping clusters in a NIFTI volume by voxel matching.\n",
    "    \n",
    "    Arguments:\n",
    "        cluster_data(numpy array): Input numpy of data\n",
    "        atlas_data(numpy array): Numpy array of labeled surface vertices for some specific hemisphere\n",
    "        atlas_dict(dict): Dictionary of label IDs to ROI names\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs overlapped by cluster(s)\n",
    "    '''\n",
    "    \n",
    "    # Flatten matrices\n",
    "    cluster_data = cluster_data.flatten(order='C')\n",
    "    atlas_data = atlas_data.flatten(order='C')\n",
    "    \n",
    "    tmp_list = list()\n",
    "    roi_list = list()\n",
    "    \n",
    "    for idx,val in enumerate(cluster_data):\n",
    "        if cluster_data[idx] == 0:\n",
    "            atlas_data[idx] = 0\n",
    "            \n",
    "    for i in np.unique(atlas_data)[1:]:\n",
    "        tmp_list = atlas_dict[i]\n",
    "        roi_list.append(tmp_list)\n",
    "        \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spread(file,out_file,roi_list):\n",
    "    '''\n",
    "    Writes the contents or roi_list to a spreadsheet.\n",
    "    \n",
    "    Arguments:\n",
    "        file (file): Input CIFTI file\n",
    "        out_file (file): Output csv file name and path. This file need not exist at runtime.\n",
    "        roi_list(list): List of ROIs to write to file\n",
    "    Returns: \n",
    "        out_file (csv file): Output csv file name and path.\n",
    "    '''\n",
    "    \n",
    "    # Strip csv file extension from output file name\n",
    "    if '.csv' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    elif '.tsv' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    elif '.txt' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    else:\n",
    "        out_file = out_file + '.csv'\n",
    "    \n",
    "    # Construct image dictionary\n",
    "    file = os.path.abspath(file)\n",
    "    img_dict = {\"File\":file,\n",
    "         \"ROIs\":[roi_list]}\n",
    "    \n",
    "    # Create dataframe from image dictionary\n",
    "    df = pd.DataFrame.from_dict(img_dict,orient='columns')\n",
    "    \n",
    "    # Write output CSV file\n",
    "    if os.path.exists(out_file):\n",
    "        df.to_csv(out_file, sep=\",\", header=False, index=False, mode='a')\n",
    "    else:\n",
    "        df.to_csv(out_file, sep=\",\", header=True, index=False, mode='w')\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_vol(nii_file,out_file,thresh = 0.95, dist = 0, vol_atlas_num = 3, nii_atlas = \"\", atlas_info = \"\"):\n",
    "    '''\n",
    "    Identifies ROIs that have overlap with some cluster(s) from the input NIFTI file.\n",
    "    \n",
    "    Arguments:\n",
    "        nii_file(NIFTI file): Input NIFTI volume file\n",
    "        out_file(file): Name for output CSV\n",
    "        thresh(float): Threshold values below this value\n",
    "        dist(float): Minimum distance between two or more clusters\n",
    "        vol_atlas_num(int): Atlas to be used in FSL's `atlasquery`. Number corresponds to an atlas. See FSL's `atlasquery` help menu for details.\n",
    "        nii_atlas(NIFTI file): NIFTI atlas file\n",
    "        atlas_info(file): Corresponding CSV key, value pairs of ROIs for atlas file\n",
    "    Returns:\n",
    "      out_filefile(file): Output CSV file\n",
    "    '''\n",
    "    \n",
    "    if nii_atlas and atlas_info:\n",
    "        # Read atlas data and info\n",
    "        [atlas_data,atlas_dict] = load_atlas_data(nii_atlas,atlas_info)\n",
    "\n",
    "        # Read NIFTI data and find clusters\n",
    "        img_data = load_nii_vol(nii_file,thresh,dist)\n",
    "\n",
    "        # Identify cluster and ROI overlaps\n",
    "        roi_list = get_roi_name(img_data,atlas_data,atlas_dict)\n",
    "    else:\n",
    "        roi_list = vol_clust(nii_file,thresh,dist,vol_atlas_num)\n",
    "    \n",
    "    # Write spreadsheet to file\n",
    "    if len(roi_list) != 0:\n",
    "        out_file = write_spread(nii_file,out_file,roi_list)\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_file = \"test.files/test.file.nii.gz\"\n",
    "nii_atlas = \"test.files/Atlas_ROIs.2.nii.gz\"\n",
    "atlas_info = \"test.files/Atlas_ROIs.2.csv\"\n",
    "out_file = \"test.3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.3.csv'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_vol(nii_file=nii_file,out_file=out_file,thresh = 1.77, dist = 20, vol_atlas_num = 4, nii_atlas = nii_atlas, atlas_info = atlas_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
